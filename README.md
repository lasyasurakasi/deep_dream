# Deep Dream — Visualizing a Neural Network’s Imagination

What happens when you show a neural network a picture... and then ask it to "dream"?

This project is a fascinating technique that visualizes the patterns learned by convolutional neural networks (CNNs). By amplifying the features the network sees in an image, we get results that are trippy, surreal — and deeply insightful.

---

## How It Mimics the Human Brain

Neural networks are inspired by the structure of the **human visual cortex**. Just like how your brain processes what you see in stages — edges, colors, patterns, faces — a CNN processes an image through multiple layers of neurons.

Each layer specializes in detecting a certain kind of feature:

- **Early layers**: Detect basic shapes like edges and textures
- **Middle layers**: Recognize patterns like eyes, feathers, or fur
- **Deeper layers**: Understand complex concepts like dog faces or buildings

In Deep Dream, we reverse the usual process. Instead of training the network to recognize an object, we **lock onto a neuron (or set of neurons)** and ask the network:

> “What would the image look like if this neuron was really, *really* excited?”

The result is a form of *synthetic hallucination* — like the machine is dreaming out loud. Much like how our brains might fill in blanks when daydreaming or dreaming at night, Deep Dream exaggerates the features it already knows, leading to abstract, layered, and often psychedelic visuals.

It’s not just eye-candy. It’s **interpretability**, **neuroscience**, and **art**, rolled into one.

---

## Tech Stack

- **TensorFlow 1.x** — for fine-grained control over model operations
- **InceptionV1 (GoogLeNet)** — pre-trained CNN model trained on ImageNet
- **Python 3.10**
- **PIL + Matplotlib** — image processing and plotting
- **Jupyter Notebook** — interactive experiments

---

## What You’ll See

You’ll start with a normal image — say, a photo of your cat.

Then Deep Dream will feed it through the network and modify the image slightly to **amplify the activations** of certain layers.

Run it multiple times, and it starts to "hallucinate" familiar patterns into the image — fur becomes feathers, eyes appear where they shouldn’t, trees morph into towers.

It's not random. It’s the model revealing what it *knows* — and what it *wants* to see.

---

## Getting Started

1. **Clone the repo**
   ```bash
   git clone https://github.com/lasyasurakasi/deep_dream.git
   cd deep_dream
